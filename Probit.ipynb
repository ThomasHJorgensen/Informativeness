{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Informativeness of Estimation Moments\n",
    "This notebook illustrates the ideas in \"*The Informativeness of Estimation Moments*\" to appear in *Journal of Applied Econometrics* by Bo Honoré, Thomas H. Jørgensen and Áureo de Paula.\n",
    "\n",
    "The code replicates the Probit example in that paper. Exact numbers differ due to the original implementation being in Matlab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import scipy.stats as sci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define moment function used in estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moment function\n",
    "def mom_funci(beta,y,x):\n",
    "    \n",
    "    residual = y-sci.norm.cdf(x @ beta);\n",
    "    \n",
    "    # allocate memory to store moments\n",
    "    n,k = x.shape\n",
    "    momi = np.nan + np.zeros((n,k*(k+1)//2)) \n",
    "    \n",
    "    # loop through all elements in x and calcilate moments on individual level\n",
    "    ii=0\n",
    "    for i1 in range(k):\n",
    "        for i2 in range(i1,k):\n",
    "            momi[:,ii]=residual*x[:,i1]*x[:,i2]\n",
    "            ii=ii+1\n",
    "\n",
    "    return momi\n",
    "\n",
    "def mom_func(beta,y,x):\n",
    "    \n",
    "    # return average moment \n",
    "    momi = mom_funci(beta,y,x)\n",
    "    return np.mean(momi,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate synthetic discrete choice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of simulations and seed\n",
    "n = 10_000_000 \n",
    "np.random.seed(2020)\n",
    "\n",
    "#setup the beta-parameters with desired varaince and covariance structure\n",
    "rho = 0.5 # must be positive in program\n",
    "r = np.sqrt(rho/(1.0-rho))\n",
    "k = 3\n",
    "beta = np.ones(k)/np.sqrt(2+2*rho)\n",
    "\n",
    "# generate explanatory varaibles, x\n",
    "x = np.random.normal(size=(n,k))\n",
    "a = np.random.normal(size=n)\n",
    "\n",
    "x[:,0]=np.ones(n)\n",
    "x[:,1]=(x[:,1]+a*r)/np.sqrt(1+r*r)\n",
    "x[:,2]=(x[:,2]+a*r)/np.sqrt(1+r*r)\n",
    "\n",
    "# generate binary outcome\n",
    "y = (x @ beta + np.random.normal(size=n)) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate required objects ($S$, $G$) at $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte covaraince matrix of estimation moments\n",
    "momi = mom_funci(beta,y,x)\n",
    "S = np.cov(momi,rowvar=False)\n",
    "\n",
    "# Calculate the numerical gradient of the objective function at beta\n",
    "def num_grad(fun,theta,num_mom,step=1.0e-4,**kargs):\n",
    "    # Calculate numerical gradient for all parameters\n",
    "    num_par  = len(theta)\n",
    "    grad = np.nan + np.zeros((num_mom,num_par))\n",
    "    \n",
    "    for i in range(num_par):\n",
    "        var_now      = np.zeros(num_par)\n",
    "        var_now[i]   = 1\n",
    "\n",
    "        forward  = fun(theta+step*var_now,**kargs);\n",
    "        backward = fun(theta-step*var_now,**kargs);\n",
    "\n",
    "        grad[:,i]   = (forward-backward)/(2*step)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "grad = num_grad(mom_func,beta,len(S),step=1.0e-4,y=y,x=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sensitivity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity measures\n",
    "def sensitivity(grad,S,W):\n",
    "    \n",
    "    sens = dict()\n",
    "    \n",
    "    # calculate objects re-used below\n",
    "    GW       = grad.T @ W\n",
    "    GWG      = GW @ grad\n",
    "    GWG_inv  = np.linalg.inv(GWG)\n",
    "    \n",
    "    GSi  = grad.T @ np.linalg.inv(S)\n",
    "    GSiG = GSi @ grad\n",
    "    \n",
    "    Avar    = GWG_inv @ (GW @ S @ GW.T) @ GWG_inv\n",
    "    AvarOpt = np.linalg.inv(GSiG)\n",
    "    \n",
    "    # sensitivity measures\n",
    "    sens['M1'] = - GWG_inv @ GW\n",
    "    \n",
    "    num_mom = len(S)\n",
    "    num_par = len(grad[0])\n",
    "    shape = (num_par,num_mom)\n",
    "    sens['M2'] = np.nan + np.zeros(shape)\n",
    "    sens['M3'] = np.nan + np.zeros(shape)\n",
    "    sens['M4'] = np.nan + np.zeros(shape)\n",
    "    sens['M5'] = np.nan + np.zeros(shape)\n",
    "    sens['M6'] = np.nan + np.zeros(shape)\n",
    "    \n",
    "    sens['M2e'] = np.nan + np.zeros(shape)\n",
    "    sens['M3e'] = np.nan + np.zeros(shape)\n",
    "    sens['M4e'] = np.nan + np.zeros(shape)\n",
    "    sens['M5e'] = np.nan + np.zeros(shape)\n",
    "    sens['M6e'] = np.nan + np.zeros(shape)\n",
    "    \n",
    "    for k in range(num_mom):\n",
    "        # pick out the kk'th element: Okk\n",
    "        O      = np.zeros((num_mom,num_mom))\n",
    "        O[k,k] = 1\n",
    "        \n",
    "        M2kk     = (np.linalg.inv(GSiG) @ (GSi @ O @ GSi.T)) @ np.linalg.inv(GSiG)         # num_par-by-num_par\n",
    "        M3kk     = GWG_inv @ (GW @ O @ GW.T) @ GWG_inv\n",
    "        M6kk     =  - GWG_inv @ (grad.T@ O @ grad) @ Avar \\\n",
    "                    + GWG_inv @ (grad.T @ O @ S @ W @ grad) @ GWG_inv \\\n",
    "                    + GWG_inv @ (grad.T @ W @ S @ O @ grad) @ GWG_inv \\\n",
    "                    - Avar @ (grad.T @ O @ grad) @ GWG_inv   # NumPar-by-NumPar\n",
    "        \n",
    "        sens['M2'][:,k]  = np.diag(M2kk) # store only the diagonal\n",
    "        sens['M3'][:,k]  = np.diag(M3kk) # store only the diagonal\n",
    "        sens['M6'][:,k]  = np.diag(M6kk) # store only the diagonal\n",
    "        \n",
    "        sens['M2e'][:,k]  = sens['M2'][:,k]/np.diag(AvarOpt) * S[k,k] # store only the diagonal\n",
    "        sens['M3e'][:,k]  = sens['M3'][:,k]/np.diag(Avar) * S[k,k]    # store only the diagonal\n",
    "        sens['M6e'][:,k]  = sens['M6'][:,k]/np.diag(Avar) * W[k,k]    #  store only the diagonal\n",
    "        \n",
    "        # remove the kth moment from the weight matrix and\n",
    "        # calculate the asymptotic variance without this moment\n",
    "        W_now      = W.copy()\n",
    "        W_now[k,:] = 0\n",
    "        W_now[:,k] = 0\n",
    "        \n",
    "        GW_now   = grad.T@W_now\n",
    "        GWG_now  = GW_now@grad\n",
    "        Avar_now = (np.linalg.inv(GWG_now) @ (GW_now@S@GW_now.T)) @ np.linalg.inv(GWG_now)\n",
    "        \n",
    "        sens['M4'][:,k]  = np.diag(Avar_now) - np.diag(Avar)\n",
    "        sens['M4e'][:,k] = sens['M4'][:,k] / np.diag(Avar)\n",
    "        \n",
    "        # optimal version\n",
    "        S_now = np.delete(S,k,axis=0)\n",
    "        S_now = np.delete(S_now,k,axis=1)\n",
    "        grad_now = np.delete(grad,k,axis=0)\n",
    "        AvarOpt_now = np.linalg.inv((grad_now.T @ np.linalg.inv(S_now)) @ grad_now)\n",
    "        sens['M5'][:,k]  = np.diag(AvarOpt_now) - np.diag(AvarOpt)\n",
    "        sens['M5e'][:,k] = sens['M5'][:,k] / np.diag(AvarOpt)\n",
    "    \n",
    "    return sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal weighting matrix\n",
    "W_opt = np.linalg.inv(S)\n",
    "sens_opt = sensitivity(grad,S,W_opt)\n",
    "\n",
    "# alternative diagonal weigting matrix\n",
    "W = np.linalg.inv(np.diag(np.diag(S)));\n",
    "sens = sensitivity(grad,S,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.10315270e+00, 8.78792726e-02, 8.74665631e-02, 2.98777341e-03,\n",
       "        4.27540262e-03, 2.72210840e-03],\n",
       "       [5.88726908e-02, 1.20963174e+00, 4.59410115e-02, 3.04011423e-03,\n",
       "        4.54749958e-04, 2.67789913e-04],\n",
       "       [5.94956727e-02, 4.57366611e-02, 1.20702823e+00, 2.69201749e-04,\n",
       "        4.83812415e-04, 2.72471938e-03]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens['M2e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.651282  , 0.10085313, 0.1008842 , 0.08049781, 0.012906  ,\n",
       "        0.08013231],\n",
       "       [0.07040271, 0.81716034, 0.03589065, 0.03634127, 0.03443829,\n",
       "        0.03898091],\n",
       "       [0.07031687, 0.03581351, 0.81727943, 0.03892429, 0.03438723,\n",
       "        0.036492  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens['M3e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10116606,  0.00179543,  0.00209301,  0.03977895,  0.01711848,\n",
       "         0.04038018],\n",
       "       [ 0.01176726, -0.14319952,  0.00182328,  0.04395316,  0.04846761,\n",
       "         0.03718821],\n",
       "       [ 0.01160534,  0.00187896, -0.14255851,  0.03694306,  0.04837379,\n",
       "         0.04375736]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens['M6e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0767247 ,  0.34324854,  0.34147116, -0.00994256, -0.01067718,\n",
       "        -0.01077989],\n",
       "       [ 0.0406604 ,  3.80560198,  0.11447516, -0.03860138, -0.03170452,\n",
       "        -0.02825486],\n",
       "       [ 0.0411031 ,  0.11382766,  3.80250227, -0.02804604, -0.03163221,\n",
       "        -0.03818067]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens['M4e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.20357111e+00, 2.93734864e-01, 2.92638645e-01, 1.51146490e-03,\n",
       "        2.88056253e-03, 1.38124222e-03],\n",
       "       [6.42317874e-02, 4.04317201e+00, 1.53705769e-01, 1.53794325e-03,\n",
       "        3.06388849e-04, 1.35880972e-04],\n",
       "       [6.49114785e-02, 1.52873955e-01, 4.03837870e+00, 1.36184689e-04,\n",
       "        3.25969748e-04, 1.38256708e-03]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens['M5e']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}